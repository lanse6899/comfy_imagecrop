import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch.nn.functional as F

class DisplacementMapWithPanel:
    """
    Â∏¶‰∫§‰∫íÈù¢ÊùøÁöÑÁΩÆÊç¢Ë¥¥ÂõæËäÇÁÇπ
    Âü∫‰∫éÊ∑±Â∫¶ÂõæÁöÑÁΩÆÊç¢Ë¥¥ÂõæÔºåÁ±ª‰ººPhotoshopÁöÑÁΩÆÊç¢ÂäüËÉΩÔºåËÆ©Ë¥¥ÂõæË¥¥ÂêàÁì∂Â≠êË°®Èù¢
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "texture": ("IMAGE",),  # Ë¶ÅË¥¥ÁöÑÁ∫πÁêÜÂõæ
                "displacement_map": ("IMAGE",),  # Ê∑±Â∫¶Âõæ/ÁΩÆÊç¢Âõæ
                "strength": ("FLOAT", {
                    "default": 10.0,
                    "min": 0.0,
                    "max": 100.0,
                    "step": 0.1
                }),
                "horizontal_scale": ("FLOAT", {
                    "default": 1.0,
                    "min": -2.0,
                    "max": 2.0,
                    "step": 0.1
                }),
                "vertical_scale": ("FLOAT", {
                    "default": 1.0,
                    "min": -2.0,
                    "max": 2.0,
                    "step": 0.1
                }),
                "blur_radius": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 20,
                    "step": 1
                }),
                "texture_offset_x": ("INT", {
                    "default": 0,
                    "min": -4096,
                    "max": 4096,
                    "step": 1,
                    "display": "hidden"  # ÈöêËóèÊòæÁ§∫ÔºåÁî±Èù¢ÊùøÊéßÂà∂
                }),
                "texture_offset_y": ("INT", {
                    "default": 0,
                    "min": -4096,
                    "max": 4096,
                    "step": 1,
                    "display": "hidden"  # ÈöêËóèÊòæÁ§∫ÔºåÁî±Èù¢ÊùøÊéßÂà∂
                }),
                "texture_scale": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.1,
                    "max": 5.0,
                    "step": 0.01,
                    "display": "hidden"  # ÈöêËóèÊòæÁ§∫ÔºåÁî±Èù¢ÊùøÊéßÂà∂
                }),
                "texture_rotation": ("FLOAT", {
                    "default": 0.0,
                    "min": -180.0,
                    "max": 180.0,
                    "step": 0.1,
                    "display": "hidden"  # ÈöêËóèÊòæÁ§∫ÔºåÁî±Èù¢ÊùøÊéßÂà∂
                }),
                "texture_width": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 8192,
                    "step": 1,
                    "display": "hidden"  # 0Ë°®Á§∫‰ΩøÁî®ÂéüÂßãÂÆΩÂ∫¶
                }),
                "texture_height": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 8192,
                    "step": 1,
                    "display": "hidden"  # 0Ë°®Á§∫‰ΩøÁî®ÂéüÂßãÈ´òÂ∫¶
                }),
            },
            "optional": {
                "background": ("IMAGE",),  # ËÉåÊôØÂõæÔºàÁì∂Â≠êÔºâÔºåÂèØÈÄâ
                "blend_mode": ([
                    "normal",           # Ê≠£Â∏∏
                    "multiply",         # Ê≠£ÁâáÂè†Â∫ï
                    "screen",           # Êª§Ëâ≤
                    "overlay",          # Âè†Âä†
                    "soft_light",       # ÊüîÂÖâ
                    "hard_light",       # Âº∫ÂÖâ
                    "color_dodge",      # È¢úËâ≤ÂáèÊ∑°
                    "color_burn",       # È¢úËâ≤Âä†Ê∑±
                    "darken",           # ÂèòÊöó
                    "lighten",          # Âèò‰∫Æ
                    "difference",        # Â∑ÆÂÄº
                    "exclusion",         # ÊéíÈô§
                    "linear_burn",       # Á∫øÊÄßÂä†Ê∑±
                    "linear_dodge",      # Á∫øÊÄßÂáèÊ∑°ÔºàÊ∑ªÂä†Ôºâ
                    "vivid_light",      # ‰∫ÆÂÖâ
                    "linear_light",      # Á∫øÊÄßÂÖâ
                    "pin_light",        # ÁÇπÂÖâ
                    "hard_mix",         # ÂÆûËâ≤Ê∑∑Âêà
                ], {
                    "default": "normal"
                }),
                "opacity": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "protect_highlights": ("BOOLEAN", {
                    "default": True
                }),
                "highlight_threshold": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "highlight_range": ("FLOAT", {
                    "default": 0.2,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "highlight_strength": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "highlight_blend_mode": ([
                    "normal", "multiply", "screen", "overlay", "soft_light", "hard_light",
                    "color_dodge", "color_burn", "darken", "lighten", "difference", "exclusion",
                    "linear_burn", "linear_dodge", "vivid_light", "linear_light", "pin_light", "hard_mix",
                ], {
                    "default": "soft_light"
                }),
                "protect_shadows": ("BOOLEAN", {
                    "default": True
                }),
                "shadow_threshold": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "shadow_range": ("FLOAT", {
                    "default": 0.2,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "shadow_strength": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01
                }),
                "shadow_blend_mode": ([
                    "normal", "multiply", "screen", "overlay", "soft_light", "hard_light",
                    "color_dodge", "color_burn", "darken", "lighten", "difference", "exclusion",
                    "linear_burn", "linear_dodge", "vivid_light", "linear_light", "pin_light", "hard_mix",
                ], {
                    "default": "multiply"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "IMAGE")
    RETURN_NAMES = ("result_image", "preview_image")
    FUNCTION = "apply_displacement"
    CATEGORY = "üîµBB image crop"
    
    def apply_displacement(self, texture, displacement_map, strength, horizontal_scale, vertical_scale, blur_radius, 
                          texture_offset_x=0, texture_offset_y=0, texture_scale=1.0, texture_rotation=0.0,
                          texture_width=0, texture_height=0,
                          background=None, blend_mode="normal", opacity=1.0,
                          protect_highlights=True, highlight_threshold=0.7, highlight_range=0.2, highlight_strength=0.5,
                          highlight_blend_mode="soft_light",
                          protect_shadows=True, shadow_threshold=0.3, shadow_range=0.2, shadow_strength=0.5,
                          shadow_blend_mode="multiply"):
        """
        Â∫îÁî®ÁΩÆÊç¢Ë¥¥ÂõæÔºåÂ∞ÜÁ∫πÁêÜË¥¥Âà∞Ë°®Èù¢
        
        Args:
            texture: Ë¶ÅË¥¥ÁöÑÁ∫πÁêÜÂõæ (B, H, W, C)
            displacement_map: Ê∑±Â∫¶Âõæ/ÁΩÆÊç¢Âõæ (B, H, W, C)
            strength: ÁΩÆÊç¢Âº∫Â∫¶
            horizontal_scale: Ê∞¥Âπ≥ÊñπÂêëÁº©Êîæ
            vertical_scale: ÂûÇÁõ¥ÊñπÂêëÁº©Êîæ
            blur_radius: Ê®°Á≥äÂçäÂæÑÔºàÁî®‰∫éÂπ≥ÊªëÁΩÆÊç¢Ôºâ
            background: ËÉåÊôØÂõæÔºàÁì∂Â≠êÔºâÔºåÂèØÈÄâ
            blend_mode: Ê∑∑ÂêàÊ®°Âºè
            opacity: ‰∏çÈÄèÊòéÂ∫¶
        """
        # ËΩ¨Êç¢‰∏∫tensorÊ†ºÂºè (B, C, H, W)
        texture_tensor = texture.permute(0, 3, 1, 2).float()
        disp_tensor = displacement_map.permute(0, 3, 1, 2).float()
        
        # ‰øùÂ≠òÂéüÂßãÁ∫πÁêÜÂõæÂ∞∫ÂØ∏
        original_tex_h, original_tex_w = texture_tensor.shape[2], texture_tensor.shape[3]
        
        # Á°ÆÂÆöÁõÆÊ†áÂ∞∫ÂØ∏Ôºà‰ºòÂÖà‰ΩøÁî®ÊåáÂÆöÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶Ôºâ
        if texture_width > 0 and texture_height > 0:
            # ‰ΩøÁî®ÊåáÂÆöÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶
            target_h = texture_height
            target_w = texture_width
        elif texture_scale != 1.0:
            # ‰ΩøÁî®Áº©ÊîæÊØî‰æã
            target_h = int(original_tex_h * texture_scale)
            target_w = int(original_tex_w * texture_scale)
        else:
            # ‰øùÊåÅÂéüÂßãÂ∞∫ÂØ∏
            target_h = original_tex_h
            target_w = original_tex_w
        
        # Â¶ÇÊûúÂ∞∫ÂØ∏ÂèëÁîüÂèòÂåñÔºåË∞ÉÊï¥Á∫πÁêÜÂõæ
        if target_h != original_tex_h or target_w != original_tex_w:
            texture_tensor = F.interpolate(
                texture_tensor,
                size=(target_h, target_w),
                mode='bilinear',
                align_corners=False
            )
        
        # Á°ÆÂÆöËæìÂá∫Â∞∫ÂØ∏Ôºà‰ºòÂÖà‰ΩøÁî®ËÉåÊôØÂõæÂ∞∫ÂØ∏Ôºâ
        if background is not None:
            bg_tensor = background.permute(0, 3, 1, 2).float()
            target_height, target_width = bg_tensor.shape[2], bg_tensor.shape[3]
        else:
            # Ê≤°ÊúâËÉåÊôØÂõæÊó∂Ôºå‰ΩøÁî®Áº©ÊîæÂêéÁöÑÁ∫πÁêÜÂõæÂ∞∫ÂØ∏
            target_height, target_width = texture_tensor.shape[2], texture_tensor.shape[3]
            bg_tensor = None
        
        # Á°Æ‰øùÁΩÆÊç¢ÂõæÂ∞∫ÂØ∏‰∏éÁ∫πÁêÜÂõæÂ∞∫ÂØ∏‰∏ÄËá¥Ôºà‰ΩøÁî®Áº©ÊîæÂêéÁöÑÁ∫πÁêÜÂõæÂ∞∫ÂØ∏Ôºâ
        tex_h, tex_w = texture_tensor.shape[2], texture_tensor.shape[3]
        if disp_tensor.shape[2:] != (tex_h, tex_w):
            # Ë∞ÉÊï¥ÁΩÆÊç¢ÂõæÂ∞∫ÂØ∏Âà∞Á∫πÁêÜÂõæÂ∞∫ÂØ∏
            disp_tensor = F.interpolate(
                disp_tensor, 
                size=(tex_h, tex_w),
                mode='bilinear',
                align_corners=False
            )
        
        # ËΩ¨Êç¢‰∏∫ÁÅ∞Â∫¶ÂõæÔºàÂèñRGBÂπ≥ÂùáÂÄºÔºâ
        if disp_tensor.shape[1] == 3:
            disp_gray = disp_tensor.mean(dim=1, keepdim=True)
        else:
            disp_gray = disp_tensor[:, 0:1, :, :]
        
        # ÂΩí‰∏ÄÂåñÂà∞[-1, 1]ËåÉÂõ¥
        disp_gray = (disp_gray - 0.5) * 2.0
        
        # Â∫îÁî®Ê®°Á≥äÔºàÂèØÈÄâÔºâ
        if blur_radius > 0:
            kernel_size = blur_radius * 2 + 1
            # ÂàõÂª∫È´òÊñØÊ†∏
            sigma = blur_radius / 3.0
            x = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2
            gaussian = torch.exp(-(x ** 2) / (2 * sigma ** 2))
            gaussian = gaussian / gaussian.sum()
            gaussian = gaussian.view(1, 1, 1, kernel_size).to(disp_gray.device)
            
            # Ê∞¥Âπ≥ÂíåÂûÇÁõ¥ÊñπÂêëÊ®°Á≥ä
            disp_gray = F.conv2d(disp_gray, gaussian, padding=(0, kernel_size // 2))
            disp_gray = F.conv2d(disp_gray, gaussian.transpose(-1, -2), padding=(kernel_size // 2, 0))
        
        # ËÆ°ÁÆó‰ΩçÁßªÈáè
        batch_size, channels, height, width = texture_tensor.shape
        
        # ÂàõÂª∫ÂùêÊ†áÁΩëÊ†ºÔºàÂÖºÂÆπ‰∏çÂêåPyTorchÁâàÊú¨Ôºâ
        try:
            y_coords, x_coords = torch.meshgrid(
                torch.arange(height, dtype=torch.float32, device=texture_tensor.device),
                torch.arange(width, dtype=torch.float32, device=texture_tensor.device),
                indexing='ij'
            )
        except TypeError:
            # ÊóßÁâàÊú¨PyTorch‰∏çÊîØÊåÅindexingÂèÇÊï∞
            y_coords, x_coords = torch.meshgrid(
                torch.arange(height, dtype=torch.float32, device=texture_tensor.device),
                torch.arange(width, dtype=torch.float32, device=texture_tensor.device)
            )
            # ‰∫§Êç¢‰ª•ÂåπÈÖçijÁ¥¢Âºï
            y_coords, x_coords = y_coords, x_coords
        
        # Êâ©Â±ïÁª¥Â∫¶‰ª•ÂåπÈÖçbatch
        y_coords = y_coords.unsqueeze(0).expand(batch_size, -1, -1)
        x_coords = x_coords.unsqueeze(0).expand(batch_size, -1, -1)
        
        # ËÆ°ÁÆó‰ΩçÁßª
        # ÁΩÆÊç¢ÂõæÁöÑÂÄºÔºöÁôΩËâ≤(1.0)Ë°®Á§∫ÂêëÂâçÔºåÈªëËâ≤(-1.0)Ë°®Á§∫ÂêëÂêé
        # ÂØπ‰∫éXÊñπÂêëÔºöÊ≠£ÂÄºÂêëÂè≥ÔºåË¥üÂÄºÂêëÂ∑¶
        # ÂØπ‰∫éYÊñπÂêëÔºöÊ≠£ÂÄºÂêë‰∏ãÔºåË¥üÂÄºÂêë‰∏ä
        
        disp_x = disp_gray.squeeze(1) * strength * horizontal_scale
        disp_y = disp_gray.squeeze(1) * strength * vertical_scale
        
        # Â∫îÁî®‰ΩçÁßª
        new_x = x_coords + disp_x
        new_y = y_coords + disp_y
        
        # ÂΩí‰∏ÄÂåñÂùêÊ†áÂà∞[-1, 1]ËåÉÂõ¥Ôºàgrid_sampleË¶ÅÊ±ÇÔºâ
        new_x_norm = (new_x / (width - 1)) * 2.0 - 1.0
        new_y_norm = (new_y / (height - 1)) * 2.0 - 1.0
        
        # ÂàõÂª∫ÈááÊ†∑ÁΩëÊ†º
        grid = torch.stack([new_x_norm, new_y_norm], dim=-1)
        
        # ‰ΩøÁî®grid_sampleËøõË°åÈááÊ†∑ÔºàÂèåÁ∫øÊÄßÊèíÂÄºÔºâ
        warped_texture = F.grid_sample(
            texture_tensor,
            grid,
            mode='bilinear',
            padding_mode='border',
            align_corners=False
        )
        
        # ËΩ¨Êç¢Âõû (B, H, W, C) Ê†ºÂºè
        warped_texture = warped_texture.permute(0, 2, 3, 1)
        
        # Â∫îÁî®Á∫πÁêÜÂõæÊóãËΩ¨ÔºàÂ¶ÇÊûúÊúâÊóãËΩ¨Ôºâ
        if texture_rotation != 0.0:
            # Â∞ÜtensorËΩ¨Êç¢‰∏∫PILÂõæÂÉèËøõË°åÊóãËΩ¨
            warped_pil = self.tensor_to_pil(warped_texture[0])
            rotated_pil = warped_pil.rotate(-texture_rotation, expand=False, resample=Image.Resampling.BICUBIC, fillcolor=(0, 0, 0))
            warped_texture = self.pil_to_tensor(rotated_pil)
        
        # Â∫îÁî®Á∫πÁêÜÂõæÂÅèÁßªÔºàÂ¶ÇÊûúÊúâËÉåÊôØÂõæÔºâ
        if bg_tensor is not None:
            # ÂàõÂª∫‰∏éËÉåÊôØÂõæÁõ∏ÂêåÂ∞∫ÂØ∏ÁöÑÁ∫πÁêÜÂõæÂ±Ç
            offset_texture = torch.zeros_like(bg_tensor.permute(0, 2, 3, 1))
            bg_h, bg_w = offset_texture.shape[1], offset_texture.shape[2]
            tex_h, tex_w = warped_texture.shape[1], warped_texture.shape[2]
            
            # ËÆ°ÁÆóÁ≤òË¥¥‰ΩçÁΩÆÔºàÂ±Ö‰∏≠ + ÂÅèÁßªÔºâ
            center_x = bg_w // 2
            center_y = bg_h // 2
            tex_center_x = tex_w // 2
            tex_center_y = tex_h // 2
            
            # ËÆ°ÁÆóÁ≤òË¥¥ÁöÑËµ∑Âßã‰ΩçÁΩÆ
            start_x = center_x - tex_center_x + texture_offset_x
            start_y = center_y - tex_center_y + texture_offset_y
            
            # ËÆ°ÁÆóÂèØËßÅÂå∫Âüü
            visible_start_x = max(0, start_x)
            visible_start_y = max(0, start_y)
            visible_end_x = min(bg_w, start_x + tex_w)
            visible_end_y = min(bg_h, start_y + tex_h)
            
            # ËÆ°ÁÆó‰ªéÁ∫πÁêÜÂõæ‰∏≠ÂèñÁöÑÈÉ®ÂàÜ
            tex_start_x = visible_start_x - start_x
            tex_start_y = visible_start_y - start_y
            tex_end_x = tex_start_x + (visible_end_x - visible_start_x)
            tex_end_y = tex_start_y + (visible_end_y - visible_start_y)
            
            if visible_end_x > visible_start_x and visible_end_y > visible_start_y:
                # Á≤òË¥¥Á∫πÁêÜÂõæÂà∞ÂÅèÁßª‰ΩçÁΩÆ
                offset_texture[:, visible_start_y:visible_end_y, visible_start_x:visible_end_x, :] = \
                    warped_texture[:, tex_start_y:tex_end_y, tex_start_x:tex_end_x, :]
            warped_texture = offset_texture
        
        # Á°Æ‰øùÂÄºÂú®[0, 1]ËåÉÂõ¥ÂÜÖ
        warped_texture = torch.clamp(warped_texture, 0.0, 1.0)
        
        # Â¶ÇÊûúÊúâËÉåÊôØÂõæÔºåËøõË°åÊ∑∑Âêà
        if bg_tensor is not None:
            background = bg_tensor.permute(0, 2, 3, 1)
            result = self._blend_images(
                background, warped_texture, blend_mode, opacity,
                protect_highlights, highlight_threshold, highlight_range, highlight_strength, highlight_blend_mode,
                protect_shadows, shadow_threshold, shadow_range, shadow_strength, shadow_blend_mode
            )
        else:
            result = warped_texture
        
        # ÁîüÊàêÈ¢ÑËßàÂõæÂÉè
        result_pil = self.tensor_to_pil(result[0])
        if len(displacement_map.shape) == 4:
            disp_pil = self.tensor_to_pil(displacement_map[0])
        else:
            disp_pil = self.tensor_to_pil(displacement_map)
        
        preview_image = self.create_preview(
            result_pil, disp_pil, strength, horizontal_scale, vertical_scale
        )
        
        preview_tensor = self.pil_to_tensor(preview_image)
        
        return (result, preview_tensor)
    
    def create_preview(self, result_image, displacement_map, strength, horizontal_scale, vertical_scale):
        """
        ÂàõÂª∫È¢ÑËßàÂõæÂÉèÔºåÊòæÁ§∫ÁΩÆÊç¢ÊïàÊûúÂíåÁΩÆÊç¢Âõæ‰ø°ÊÅØ
        """
        preview = result_image.copy().convert('RGB')
        draw = ImageDraw.Draw(preview)
        
        # Âú®È¢ÑËßàÂõæ‰∏äÂè†Âä†ÊòæÁ§∫ÁΩÆÊç¢ÂõæÔºàÂçäÈÄèÊòéÔºâ
        disp_overlay = displacement_map.convert('RGB')
        if disp_overlay.size != preview.size:
            disp_overlay = disp_overlay.resize(preview.size, Image.Resampling.BILINEAR)
        
        # ÂàõÂª∫ÂçäÈÄèÊòéÂè†Âä†
        overlay = Image.blend(preview, disp_overlay, 0.3)
        preview = overlay
        
        # ÁªòÂà∂‰ø°ÊÅØÊñáÊú¨
        try:
            font = ImageFont.truetype("arial.ttf", 16)
        except:
            font = None
        
        info_text = [
            f"Âº∫Â∫¶: {strength:.1f}",
            f"Ê∞¥Âπ≥: {horizontal_scale:.2f}",
            f"ÂûÇÁõ¥: {vertical_scale:.2f}"
        ]
        
        # ÁªòÂà∂‰ø°ÊÅØËÉåÊôØ
        text_height = len(info_text) * 20 + 10
        draw.rectangle([10, 10, 200, 10 + text_height], fill=(0, 0, 0, 180))
        
        # ÁªòÂà∂ÊñáÊú¨
        for i, text in enumerate(info_text):
            draw.text((20, 15 + i * 20), text, fill=(255, 255, 0), font=font)
        
        return preview
    
    def _blend_images(self, bg, fg, blend_mode, opacity,
                     protect_highlights=True, highlight_threshold=0.7, highlight_range=0.2, highlight_strength=0.5,
                     highlight_blend_mode="soft_light",
                     protect_shadows=True, shadow_threshold=0.3, shadow_range=0.2, shadow_strength=0.5,
                     shadow_blend_mode="multiply"):
        """
        Ê∑∑ÂêàËÉåÊôØÂíåÂâçÊôØÂõæÂÉèÔºåÂèÇËÄÉPhotoshopÊ∑∑ÂêàÊ®°ÂºèÁÆóÊ≥ï
        bg: ËÉåÊôØÂ±ÇÔºàÁì∂Â≠êÔºâ
        fg: ÂâçÊôØÂ±ÇÔºàË¥¥ÂõæÔºâ
        ÊîØÊåÅÈ´òÂÖâÂíåÈò¥ÂΩ±Âå∫Âüü‰ΩøÁî®‰∏çÂêåÁöÑÊ∑∑ÂêàÊ®°Âºè
        ÊîØÊåÅÊ∑∑ÂêàÈ¢úËâ≤Â∏¶ÔºàBlend IfÔºâÂäüËÉΩ
        """
        # Á°Æ‰øùbatch size‰∏ÄËá¥
        if bg.shape[0] != fg.shape[0]:
            min_batch = min(bg.shape[0], fg.shape[0])
            bg = bg[:min_batch]
            fg = fg[:min_batch]
        
        # ËÆ°ÁÆóÈ´òÂÖâÂíåÈò¥ÂΩ±ÈÅÆÁΩ©
        highlight_mask, shadow_mask = self._calculate_protection_masks(
            bg, protect_highlights, highlight_threshold, highlight_range, highlight_strength,
            protect_shadows, shadow_threshold, shadow_range, shadow_strength
        )
        
        # ËÆ°ÁÆó‰∏çÂêåÂå∫ÂüüÁöÑÊ∑∑ÂêàÁªìÊûú
        # ‰∏≠Èó¥Âå∫Âüü‰ΩøÁî®ÈªòËÆ§Ê∑∑ÂêàÊ®°Âºè
        blended_mid = self._apply_blend_mode(bg, fg, blend_mode)
        
        # È´òÂÖâÂå∫Âüü‰ΩøÁî®È´òÂÖâÊ∑∑ÂêàÊ®°Âºè
        blended_highlight = self._apply_blend_mode(bg, fg, highlight_blend_mode) if protect_highlights else blended_mid
        
        # Èò¥ÂΩ±Âå∫Âüü‰ΩøÁî®Èò¥ÂΩ±Ê∑∑ÂêàÊ®°Âºè
        blended_shadow = self._apply_blend_mode(bg, fg, shadow_blend_mode) if protect_shadows else blended_mid
        
        # Â∫îÁî®‰∏çÈÄèÊòéÂ∫¶
        result_mid = blended_mid * opacity + bg * (1 - opacity)
        result_highlight = blended_highlight * opacity + bg * (1 - opacity) if protect_highlights else result_mid
        result_shadow = blended_shadow * opacity + bg * (1 - opacity) if protect_shadows else result_mid
        
        # ‰ΩøÁî®ÈÅÆÁΩ©ËøõË°åÂå∫ÂüüÊ∑∑Âêà
        # highlight_maskÂíåshadow_maskÁöÑÂÄºË°®Á§∫ËØ•Âå∫ÂüüÁöÑÊùÉÈáç
        # ‰∏≠Èó¥Âå∫Âüü = 1 - highlight_mask - shadow_maskÔºàÂΩí‰∏ÄÂåñÂêéÔºâ
        
        # ÂΩí‰∏ÄÂåñÈÅÆÁΩ©ÔºåÁ°Æ‰øùÊÄªÂíå‰∏çË∂ÖËøá1
        total_mask = highlight_mask + shadow_mask
        total_mask = torch.clamp(total_mask, 0.0, 1.0)
        
        # ËÆ°ÁÆó‰∏≠Èó¥Âå∫ÂüüÁöÑÊùÉÈáç
        mid_mask = 1.0 - total_mask
        
        # Ê∑∑Âêà‰∏â‰∏™Âå∫Âüü
        result = (result_mid * mid_mask + 
                 result_highlight * highlight_mask + 
                 result_shadow * shadow_mask)
        
        return torch.clamp(result, 0.0, 1.0)
    
    def _calculate_protection_masks(self, bg, protect_highlights, highlight_threshold, highlight_range, highlight_strength,
                                    protect_shadows, shadow_threshold, shadow_range, shadow_strength):
        """
        ËÆ°ÁÆóÈ´òÂÖâÂíåÈò¥ÂΩ±‰øùÊä§ÈÅÆÁΩ©
        ËøîÂõû(highlight_mask, shadow_mask)ÔºöÈÅÆÁΩ©ÂÄºË°®Á§∫ËØ•Âå∫ÂüüÁöÑÊùÉÈáçÔºà0-1Ôºâ
        """
        # ËÆ°ÁÆó‰∫ÆÂ∫¶ÔºàRGBËΩ¨ÁÅ∞Â∫¶Ôºâ
        # ‰ΩøÁî®Ê†áÂáÜÊùÉÈáçÔºö0.299*R + 0.587*G + 0.114*B
        luminance = 0.299 * bg[:, :, :, 0] + 0.587 * bg[:, :, :, 1] + 0.114 * bg[:, :, :, 2]
        luminance = luminance.unsqueeze(-1)  # (B, H, W, 1)
        
        # ÂàùÂßãÂåñÈÅÆÁΩ©
        highlight_mask = torch.zeros_like(luminance)
        shadow_mask = torch.zeros_like(luminance)
        
        # È´òÂÖâÈÅÆÁΩ©
        if protect_highlights:
            # È´òÂÖâÂå∫ÂüüÔºö‰∫ÆÂ∫¶ > highlight_threshold
            highlight_start = highlight_threshold
            highlight_end = highlight_threshold + highlight_range
            
            # ÂàõÂª∫Âπ≥ÊªëËøáÊ∏°
            highlight_weight = torch.clamp((luminance - highlight_start) / (highlight_end - highlight_start + 1e-7), 0, 1)
            # Âè™‰øùÊä§Ë∂ÖËøáÈòàÂÄºÁöÑÈ´òÂÖâÂå∫Âüü
            highlight_weight = torch.where(luminance > highlight_threshold, highlight_weight, torch.zeros_like(highlight_weight))
            # Â∫îÁî®Âº∫Â∫¶
            highlight_mask = highlight_weight * highlight_strength
        
        # Èò¥ÂΩ±ÈÅÆÁΩ©
        if protect_shadows:
            # Èò¥ÂΩ±Âå∫ÂüüÔºö‰∫ÆÂ∫¶ < shadow_threshold
            shadow_end = shadow_threshold
            shadow_start = shadow_threshold - shadow_range
            
            # ÂàõÂª∫Âπ≥ÊªëËøáÊ∏°
            shadow_weight = torch.clamp((shadow_end - luminance) / (shadow_end - shadow_start + 1e-7), 0, 1)
            # Âè™‰øùÊä§‰Ωé‰∫éÈòàÂÄºÁöÑÈò¥ÂΩ±Âå∫Âüü
            shadow_weight = torch.where(luminance < shadow_threshold, shadow_weight, torch.zeros_like(shadow_weight))
            # Â∫îÁî®Âº∫Â∫¶
            shadow_mask = shadow_weight * shadow_strength
        
        # ÈôêÂà∂Âú®[0, 1]ËåÉÂõ¥ÂÜÖ
        highlight_mask = torch.clamp(highlight_mask, 0.0, 1.0)
        shadow_mask = torch.clamp(shadow_mask, 0.0, 1.0)
        
        # Êâ©Â±ïÂà∞RGBÈÄöÈÅì
        highlight_mask = highlight_mask.expand(-1, -1, -1, bg.shape[-1])
        shadow_mask = shadow_mask.expand(-1, -1, -1, bg.shape[-1])
        
        return highlight_mask, shadow_mask
    
    def _apply_blend_mode(self, bg, fg, blend_mode):
        """
        Â∫îÁî®ÊåáÂÆöÁöÑÊ∑∑ÂêàÊ®°Âºè
        ËøîÂõûÊ∑∑ÂêàÂêéÁöÑÁªìÊûú
        """
        if blend_mode == "normal":
            return fg
        elif blend_mode == "multiply":
            return bg * fg
        elif blend_mode == "screen":
            return 1 - (1 - bg) * (1 - fg)
        elif blend_mode == "overlay":
            mask = bg < 0.5
            return torch.where(mask, 2 * bg * fg, 1 - 2 * (1 - bg) * (1 - fg))
        elif blend_mode == "soft_light":
            mask = fg < 0.5
            return torch.where(
                mask,
                2 * bg * fg + bg * bg * (1 - 2 * fg),
                torch.sqrt(bg) * (2 * fg - 1) + 2 * bg * (1 - fg)
            )
        elif blend_mode == "hard_light":
            mask = fg < 0.5
            return torch.where(mask, 2 * bg * fg, 1 - 2 * (1 - bg) * (1 - fg))
        elif blend_mode == "color_dodge":
            epsilon = 1e-7
            return torch.where(
                fg >= 1.0,
                torch.ones_like(bg),
                torch.clamp(bg / (1 - fg + epsilon), 0, 1)
            )
        elif blend_mode == "color_burn":
            epsilon = 1e-7
            return torch.where(
                fg <= 0.0,
                torch.zeros_like(bg),
                torch.clamp(1 - (1 - bg) / (fg + epsilon), 0, 1)
            )
        elif blend_mode == "darken":
            return torch.minimum(bg, fg)
        elif blend_mode == "lighten":
            return torch.maximum(bg, fg)
        elif blend_mode == "difference":
            return torch.abs(bg - fg)
        elif blend_mode == "exclusion":
            return bg + fg - 2 * bg * fg
        elif blend_mode == "linear_burn":
            return torch.clamp(bg + fg - 1, 0, 1)
        elif blend_mode == "linear_dodge":
            return torch.clamp(bg + fg, 0, 1)
        elif blend_mode == "vivid_light":
            mask = fg < 0.5
            epsilon = 1e-7
            color_burn = torch.where(
                fg <= 0.0,
                torch.zeros_like(bg),
                torch.clamp(1 - (1 - bg) / (fg + epsilon), 0, 1)
            )
            color_dodge = torch.where(
                fg >= 1.0,
                torch.ones_like(bg),
                torch.clamp(bg / (1 - fg + epsilon), 0, 1)
            )
            return torch.where(mask, color_burn, color_dodge)
        elif blend_mode == "linear_light":
            return torch.clamp(bg + 2 * fg - 1, 0, 1)
        elif blend_mode == "pin_light":
            mask = fg < 0.5
            darken_result = torch.minimum(bg, 2 * fg)
            lighten_result = torch.maximum(bg, 2 * (fg - 0.5))
            return torch.where(mask, darken_result, lighten_result)
        elif blend_mode == "hard_mix":
            mask = bg < 0.5
            overlay_result = torch.where(mask, 2 * bg * fg, 1 - 2 * (1 - bg) * (1 - fg))
            return torch.where(overlay_result < 0.5, torch.zeros_like(bg), torch.ones_like(bg))
        else:
            return fg
    
    def tensor_to_pil(self, tensor):
        """Â∞ÜtensorËΩ¨Êç¢‰∏∫PILÂõæÂÉè"""
        # tensor shape: [H, W, C] Êàñ [C, H, W]
        if len(tensor.shape) == 3:
            if tensor.shape[0] == 3 or tensor.shape[0] == 1:  # [C, H, W]
                tensor = tensor.permute(1, 2, 0)  # ËΩ¨Êç¢‰∏∫ [H, W, C]
        
        # Á°Æ‰øùÂÄºÂú®0-1ËåÉÂõ¥ÂÜÖ
        tensor = torch.clamp(tensor, 0, 1)
        
        # ËΩ¨Êç¢‰∏∫numpyÊï∞ÁªÑ
        numpy_image = tensor.cpu().numpy()
        
        # ËΩ¨Êç¢‰∏∫0-255ËåÉÂõ¥
        numpy_image = (numpy_image * 255).astype(np.uint8)
        
        # ËΩ¨Êç¢‰∏∫PILÂõæÂÉè
        if len(numpy_image.shape) == 2:
            # ÁÅ∞Â∫¶ÂõæÂÉè
            pil_image = Image.fromarray(numpy_image, mode='L').convert('RGB')
        elif numpy_image.shape[2] == 1:
            # ÂçïÈÄöÈÅìÂõæÂÉè
            pil_image = Image.fromarray(numpy_image.squeeze(), mode='L').convert('RGB')
        else:
            # RGBÂõæÂÉè
            pil_image = Image.fromarray(numpy_image, mode='RGB')
        
        return pil_image
    
    def pil_to_tensor(self, pil_image):
        """Â∞ÜPILÂõæÂÉèËΩ¨Êç¢‰∏∫tensor"""
        # Á°Æ‰øùÊòØRGBÊ®°Âºè
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # ËΩ¨Êç¢‰∏∫numpyÊï∞ÁªÑ
        numpy_image = np.array(pil_image).astype(np.float32)
        
        # ÂΩí‰∏ÄÂåñÂà∞0-1ËåÉÂõ¥
        numpy_image = numpy_image / 255.0
        
        # ËΩ¨Êç¢‰∏∫tensor [H, W, C]
        tensor = torch.from_numpy(numpy_image)
        
        # Ê∑ªÂä†ÊâπÊ¨°Áª¥Â∫¶ [1, H, W, C]
        tensor = tensor.unsqueeze(0)
        
        return tensor


# ËäÇÁÇπÊò†Â∞Ñ
NODE_CLASS_MAPPINGS = {
    "DisplacementMapWithPanel": DisplacementMapWithPanel,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DisplacementMapWithPanel": "üîµBBË¥¥Âõæ",
}

