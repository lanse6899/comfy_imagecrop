import torch
import numpy as np
from PIL import Image, ImageDraw

class RatioCropWithPanel:
    """
    å¸¦æ¯”ä¾‹é€‰æ‹©çš„äº¤äº’å¼å›¾åƒå‰ªè£èŠ‚ç‚¹
    å›¾åƒå›ºå®šä¸åŠ¨ï¼Œåªç§»åŠ¨å’Œç¼©æ”¾è£å‰ªæ¡†
    æ”¯æŒå¤šç§é¢„è®¾æ¯”ä¾‹ï¼ˆ3:4, 16:9, 1:1ç­‰ï¼‰
    """
    
    # é¢„è®¾æ¯”ä¾‹
    ASPECT_RATIOS = {
        "1:1": (1.0, 1.0),
        "3:4": (3.0, 4.0),
        "4:3": (4.0, 3.0),
        "16:9": (16.0, 9.0),
        "9:16": (9.0, 16.0),
        "21:9": (21.0, 9.0),
        "9:21": (9.0, 21.0),
        "è‡ªå®šä¹‰": None,  # è‡ªå®šä¹‰æ¯”ä¾‹
    }
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "aspect_ratio": (list(cls.ASPECT_RATIOS.keys()), {
                    "default": "1:1"
                }),
                "crop_size": ("INT", {
                    "default": 512, 
                    "min": 64, 
                    "max": 2048, 
                    "step": 8
                }),
                "crop_x": ("INT", {
                    "default": 0, 
                    "min": -4096, 
                    "max": 4096, 
                    "step": 1,
                    "display": "hidden"  # éšè—æ˜¾ç¤ºï¼Œç”±é¢æ¿æ§åˆ¶
                }),
                "crop_y": ("INT", {
                    "default": 0, 
                    "min": -4096, 
                    "max": 4096, 
                    "step": 1,
                    "display": "hidden"
                }),
                "crop_scale": ("FLOAT", {
                    "default": 1.0, 
                    "min": 0.1, 
                    "max": 5.0, 
                    "step": 0.01,
                    "display": "hidden"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "IMAGE")
    RETURN_NAMES = ("cropped_image", "preview_image")
    FUNCTION = "crop_image"
    CATEGORY = "ğŸ”µBB image crop"
    
    def crop_image(self, image, aspect_ratio, crop_size, crop_x=0, crop_y=0, crop_scale=1.0):
        """
        æ‰§è¡Œå›¾åƒå‰ªè£å¹¶ç”Ÿæˆé¢„è§ˆ
        å›¾åƒå›ºå®šï¼Œåªç§»åŠ¨å’Œç¼©æ”¾è£å‰ªæ¡†
        """
        # è½¬æ¢tensoråˆ°PILå›¾åƒ
        if len(image.shape) == 4:
            pil_image = self.tensor_to_pil(image[0])
        else:
            pil_image = self.tensor_to_pil(image)
        
        img_width, img_height = pil_image.size
        
        # è®¡ç®—è£å‰ªæ¡†å°ºå¯¸ï¼ˆæ ¹æ®æ¯”ä¾‹å’Œç¼©æ”¾ï¼‰
        if aspect_ratio == "è‡ªå®šä¹‰":
            # è‡ªå®šä¹‰æ¯”ä¾‹ï¼šä½¿ç”¨crop_sizeä½œä¸ºå®½åº¦ï¼Œé«˜åº¦ä¹Ÿä½¿ç”¨crop_sizeï¼ˆ1:1ï¼‰
            crop_width = int(crop_size * crop_scale)
            crop_height = int(crop_size * crop_scale)
        else:
            # ä½¿ç”¨é¢„è®¾æ¯”ä¾‹
            ratio_w, ratio_h = self.ASPECT_RATIOS[aspect_ratio]
            ratio = ratio_w / ratio_h
            
            # æ ¹æ®æ¯”ä¾‹å’ŒåŸºç¡€å°ºå¯¸è®¡ç®—è£å‰ªæ¡†å°ºå¯¸
            if ratio >= 1.0:  # æ¨ªå‘
                crop_width = int(crop_size * crop_scale)
                crop_height = int(crop_size * crop_scale / ratio)
            else:  # çºµå‘
                crop_width = int(crop_size * crop_scale * ratio)
                crop_height = int(crop_size * crop_scale)
        
        # è®¡ç®—è£å‰ªèµ·å§‹ä½ç½®ï¼ˆå›¾åƒä¸­å¿ƒ + åç§»ï¼‰
        start_x = (img_width - crop_width) // 2 + crop_x
        start_y = (img_height - crop_height) // 2 + crop_y
        
        # æ‰§è¡Œå‰ªè£
        cropped_image = self.perform_crop(pil_image, start_x, start_y, crop_width, crop_height)
        
        # ç”Ÿæˆé¢„è§ˆå›¾åƒï¼ˆæ˜¾ç¤ºå‰ªè£åŒºåŸŸï¼‰
        preview_image = self.create_preview(pil_image, start_x, start_y, crop_width, crop_height)
        
        # è½¬æ¢å›tensor
        cropped_tensor = self.pil_to_tensor(cropped_image)
        preview_tensor = self.pil_to_tensor(preview_image)
        
        return (cropped_tensor, preview_tensor)
    
    def perform_crop(self, image, start_x, start_y, crop_width, crop_height):
        """æ‰§è¡Œå®é™…çš„å‰ªè£æ“ä½œ"""
        img_width, img_height = image.size
        
        # åˆ›å»ºç›®æ ‡å°ºå¯¸çš„ç”»å¸ƒ
        result = Image.new('RGB', (crop_width, crop_height), (0, 0, 0))
        
        # è®¡ç®—å¯è§åŒºåŸŸ
        visible_start_x = max(0, -start_x)
        visible_start_y = max(0, -start_y)
        visible_end_x = min(crop_width, img_width - start_x)
        visible_end_y = min(crop_height, img_height - start_y)
        
        if visible_end_x > visible_start_x and visible_end_y > visible_start_y:
            # ä»åŸå›¾å‰ªè£å¯è§éƒ¨åˆ†
            crop_from_x = max(0, start_x)
            crop_from_y = max(0, start_y)
            crop_to_x = min(img_width, start_x + crop_width)
            crop_to_y = min(img_height, start_y + crop_height)
            
            cropped_part = image.crop((crop_from_x, crop_from_y, crop_to_x, crop_to_y))
            
            # ç²˜è´´åˆ°ç»“æœå›¾åƒ
            paste_x = max(0, -start_x)
            paste_y = max(0, -start_y)
            result.paste(cropped_part, (paste_x, paste_y))
        
        return result
    
    def create_preview(self, image, start_x, start_y, crop_width, crop_height):
        """åˆ›å»ºé¢„è§ˆå›¾åƒï¼Œæ˜¾ç¤ºå‰ªè£åŒºåŸŸ"""
        preview = image.copy()
        draw = ImageDraw.Draw(preview)
        
        # ç»˜åˆ¶å‰ªè£åŒºåŸŸè¾¹æ¡†
        end_x = start_x + crop_width
        end_y = start_y + crop_height
        
        # çº¢è‰²è¾¹æ¡†
        border_width = max(3, min(preview.width, preview.height) // 200)
        for i in range(border_width):
            draw.rectangle([
                start_x - i, start_y - i, 
                end_x + i, end_y + i
            ], outline=(255, 0, 0), width=1)
        
        # ç»˜åˆ¶è§’ç‚¹æ§åˆ¶å™¨
        corner_size = 12
        corners = [
            (start_x - corner_size//2, start_y - corner_size//2),  # å·¦ä¸Š
            (end_x - corner_size//2, start_y - corner_size//2),    # å³ä¸Š
            (start_x - corner_size//2, end_y - corner_size//2),    # å·¦ä¸‹
            (end_x - corner_size//2, end_y - corner_size//2)       # å³ä¸‹
        ]
        
        for corner_x, corner_y in corners:
            draw.rectangle([
                corner_x, corner_y,
                corner_x + corner_size, corner_y + corner_size
            ], fill=(255, 255, 0), outline=(0, 0, 0), width=2)
        
        # ç»˜åˆ¶ä¸­å¿ƒåå­—çº¿
        center_x = (start_x + end_x) // 2
        center_y = (start_y + end_y) // 2
        cross_size = 20
        
        draw.line([center_x - cross_size, center_y, center_x + cross_size, center_y], 
                  fill=(0, 255, 0), width=3)
        draw.line([center_x, center_y - cross_size, center_x, center_y + cross_size], 
                  fill=(0, 255, 0), width=3)
        
        # åŠé€æ˜é®ç½©ï¼ˆå‰ªè£åŒºåŸŸå¤–ï¼‰
        mask = Image.new('RGBA', preview.size, (0, 0, 0, 120))
        mask_draw = ImageDraw.Draw(mask)
        
        # æ¸…é™¤å‰ªè£åŒºåŸŸçš„é®ç½©
        mask_draw.rectangle([start_x, start_y, end_x, end_y], fill=(0, 0, 0, 0))
        
        # åº”ç”¨é®ç½©
        preview = preview.convert('RGBA')
        preview = Image.alpha_composite(preview, mask)
        preview = preview.convert('RGB')
        
        return preview
    
    def tensor_to_pil(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
        # tensor shape: [H, W, C] æˆ– [C, H, W]
        if len(tensor.shape) == 3:
            if tensor.shape[0] == 3 or tensor.shape[0] == 1:  # [C, H, W]
                tensor = tensor.permute(1, 2, 0)  # è½¬æ¢ä¸º [H, W, C]
        
        # ç¡®ä¿å€¼åœ¨0-1èŒƒå›´å†…
        tensor = torch.clamp(tensor, 0, 1)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        numpy_image = tensor.cpu().numpy()
        
        # è½¬æ¢ä¸º0-255èŒƒå›´
        numpy_image = (numpy_image * 255).astype(np.uint8)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        if len(numpy_image.shape) == 2:
            # ç°åº¦å›¾åƒ
            pil_image = Image.fromarray(numpy_image, mode='L').convert('RGB')
        elif numpy_image.shape[2] == 1:
            # å•é€šé“å›¾åƒ
            pil_image = Image.fromarray(numpy_image.squeeze(), mode='L').convert('RGB')
        else:
            # RGBå›¾åƒ
            pil_image = Image.fromarray(numpy_image, mode='RGB')
        
        return pil_image
    
    def pil_to_tensor(self, pil_image):
        """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor"""
        # ç¡®ä¿æ˜¯RGBæ¨¡å¼
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        numpy_image = np.array(pil_image).astype(np.float32)
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        numpy_image = numpy_image / 255.0
        
        # è½¬æ¢ä¸ºtensor [H, W, C]
        tensor = torch.from_numpy(numpy_image)
        
        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ [1, H, W, C]
        tensor = tensor.unsqueeze(0)
        
        return tensor

