import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os

class ImageAnnotateWithPanel:
    """
    å›¾åƒæ ‡æ³¨èŠ‚ç‚¹
    æ”¯æŒåœ¨å›¾åƒä¸Šç‚¹å‡»æ·»åŠ å¸¦ç¼–å·çš„æ ‡è®°ç‚¹
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "marker_type": (["æ•°å­—", "å­—æ¯"], {
                    "default": "æ•°å­—"
                }),
                "marker_size": ("INT", {
                    "default": 40,
                    "min": 20,
                    "max": 100,
                    "step": 5
                }),
                "marker_color": (["è“è‰²", "çº¢è‰²", "ç»¿è‰²", "é»„è‰²", "ç´«è‰²", "æ©™è‰²", "é’è‰²", "ç²‰è‰²", "æ·±è“", "æ·±ç»¿", "æ£•è‰²", "ç°è‰²"], {
                    "default": "è“è‰²"
                }),
                "text_color": (["ç™½è‰²", "é»‘è‰²"], {
                    "default": "ç™½è‰²"
                }),
                "annotations": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "display": "hidden"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("annotated_image",)
    FUNCTION = "annotate_image"
    CATEGORY = "ğŸ”µBB image crop"
    
    def annotate_image(self, image, marker_type, marker_size, marker_color, text_color, annotations):
        """
        å›¾åƒæ ‡æ³¨ä¸»å‡½æ•°
        """
        # è½¬æ¢tensoråˆ°PILå›¾åƒ
        if len(image.shape) == 4:
            pil_image = self.tensor_to_pil(image[0])
        else:
            pil_image = self.tensor_to_pil(image)
        
        # è§£ææ ‡æ³¨æ•°æ®
        annotation_points = self.parse_annotations(annotations)
        
        # å¦‚æœæ²¡æœ‰æ ‡æ³¨ç‚¹ï¼Œè¿”å›åŸå›¾
        if not annotation_points:
            return (self.pil_to_tensor(pil_image),)
        
        # åˆ›å»ºæ ‡æ³¨å›¾åƒ
        annotated_image = self.draw_annotations(
            pil_image, annotation_points, marker_type, 
            marker_size, marker_color, text_color
        )
        
        # è½¬æ¢å›tensor
        result_tensor = self.pil_to_tensor(annotated_image)
        
        return (result_tensor,)
    
    def parse_annotations(self, annotations_str):
        """
        è§£ææ ‡æ³¨å­—ç¬¦ä¸²
        æ ¼å¼: "x1,y1;x2,y2;x3,y3"
        """
        if not annotations_str or annotations_str.strip() == "":
            return []
        
        points = []
        try:
            pairs = annotations_str.split(';')
            for pair in pairs:
                if pair.strip():
                    x, y = pair.split(',')
                    points.append((float(x), float(y)))
        except:
            return []
        
        return points
    
    def draw_annotations(self, image, points, marker_type, marker_size, marker_color, text_color):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡æ³¨
        """
        # è½¬æ¢ä¸ºRGBAä»¥æ”¯æŒæ›´å¥½çš„ç»˜åˆ¶æ•ˆæœ
        if image.mode != 'RGBA':
            result_image = image.convert('RGBA')
        else:
            result_image = image.copy()
        
        # åˆ›å»ºç»˜å›¾å±‚
        overlay = Image.new('RGBA', result_image.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # é¢œè‰²æ˜ å°„
        color_map = {
            "è“è‰²": (41, 128, 185, 255),      # å®Œå…¨ä¸é€æ˜
            "çº¢è‰²": (231, 76, 60, 255),       # é²œçº¢è‰²
            "ç»¿è‰²": (46, 204, 113, 255),      # ç¿ ç»¿è‰²
            "é»„è‰²": (241, 196, 15, 255),      # é‡‘é»„è‰²
            "ç´«è‰²": (155, 89, 182, 255),      # ç´«ç½—å…°
            "æ©™è‰²": (230, 126, 34, 255),      # æ©™è‰²
            "é’è‰²": (26, 188, 156, 255),      # é’ç»¿è‰²
            "ç²‰è‰²": (236, 112, 140, 255),     # ç²‰çº¢è‰²
            "æ·±è“": (52, 73, 94, 255),        # æ·±è“è‰²
            "æ·±ç»¿": (39, 174, 96, 255),       # æ·±ç»¿è‰²
            "æ£•è‰²": (165, 105, 79, 255),      # æ£•è‰²
            "ç°è‰²": (127, 140, 141, 255)      # ç°è‰²
        }
        
        text_color_map = {
            "ç™½è‰²": (255, 255, 255, 255),
            "é»‘è‰²": (0, 0, 0, 255)
        }
        
        marker_fill = color_map.get(marker_color, color_map["è“è‰²"])
        text_fill = text_color_map.get(text_color, text_color_map["ç™½è‰²"])
        
        # åŠ è½½å­—ä½“
        try:
            # å°è¯•åŠ è½½ç³»ç»Ÿå­—ä½“
            font_size = int(marker_size * 0.5)
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            try:
                # Windowsç³»ç»Ÿå­—ä½“
                font = ImageFont.truetype("C:/Windows/Fonts/arial.ttf", int(marker_size * 0.5))
            except:
                # ä½¿ç”¨é»˜è®¤å­—ä½“
                font = ImageFont.load_default()
        
        # ç»˜åˆ¶æ¯ä¸ªæ ‡æ³¨ç‚¹
        for i, (x, y) in enumerate(points):
            # ç”Ÿæˆæ ‡ç­¾
            if marker_type == "æ•°å­—":
                label = str(i + 1)
            else:  # å­—æ¯
                label = chr(65 + i) if i < 26 else chr(65 + (i % 26))
            
            # ç»˜åˆ¶æ ‡è®°ç‚¹ï¼ˆç±»ä¼¼åœ°å›¾æ ‡è®°çš„å½¢çŠ¶ï¼‰
            self.draw_map_marker(draw, x, y, marker_size, marker_fill, label, text_fill, font)
        
        # åˆå¹¶å›¾å±‚
        result_image = Image.alpha_composite(result_image, overlay)
        
        # è½¬æ¢å›RGB
        result_image = result_image.convert('RGB')
        
        return result_image
    
    def draw_map_marker(self, draw, x, y, size, fill_color, label, text_color, font):
        """
        ç»˜åˆ¶åœ°å›¾æ ‡è®°æ ·å¼çš„æ ‡æ³¨ç‚¹
        """
        # åœ†å½¢éƒ¨åˆ†çš„åŠå¾„
        radius = size // 2
        
        # ç»˜åˆ¶åº•éƒ¨çš„å°–è§’ï¼ˆä¸‰è§’å½¢ï¼‰
        tip_height = size // 3
        tip_points = [
            (x, y + radius + tip_height),  # åº•éƒ¨å°–ç«¯
            (x - radius // 2, y + radius),  # å·¦è¾¹
            (x + radius // 2, y + radius)   # å³è¾¹
        ]
        draw.polygon(tip_points, fill=fill_color)
        
        # ç»˜åˆ¶åœ†å½¢ä¸»ä½“
        circle_bbox = [
            x - radius, y - radius,
            x + radius, y + radius
        ]
        draw.ellipse(circle_bbox, fill=fill_color)
        
        # ç»˜åˆ¶ç™½è‰²å†…åœˆï¼ˆå¯é€‰ï¼Œå¢åŠ å±‚æ¬¡æ„Ÿï¼‰
        inner_radius = radius - 3
        if inner_radius > 0:
            inner_circle = [
                x - inner_radius, y - inner_radius,
                x + inner_radius, y + inner_radius
            ]
            # ç»˜åˆ¶åŠé€æ˜ç™½è‰²è¾¹æ¡†
            draw.ellipse(inner_circle, outline=(255, 255, 255, 180), width=2)
        
        # ç»˜åˆ¶æ–‡å­—æ ‡ç­¾
        try:
            # è·å–æ–‡å­—è¾¹ç•Œæ¡†
            bbox = draw.textbbox((0, 0), label, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            # å±…ä¸­æ–‡å­—
            text_x = x - text_width // 2
            text_y = y - text_height // 2 - radius // 4
            
            draw.text((text_x, text_y), label, fill=text_color, font=font)
        except:
            # å¦‚æœtextbboxä¸å¯ç”¨ï¼Œä½¿ç”¨æ—§æ–¹æ³•
            draw.text((x - size // 4, y - size // 4), label, fill=text_color, font=font)
    
    def tensor_to_pil(self, tensor):
        """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ"""
        if len(tensor.shape) == 3:
            if tensor.shape[0] == 3 or tensor.shape[0] == 1:
                tensor = tensor.permute(1, 2, 0)
        
        tensor = torch.clamp(tensor, 0, 1)
        numpy_image = tensor.cpu().numpy()
        numpy_image = (numpy_image * 255).astype(np.uint8)
        
        if len(numpy_image.shape) == 2:
            pil_image = Image.fromarray(numpy_image, mode='L').convert('RGB')
        elif numpy_image.shape[2] == 1:
            pil_image = Image.fromarray(numpy_image.squeeze(), mode='L').convert('RGB')
        else:
            pil_image = Image.fromarray(numpy_image, mode='RGB')
        
        return pil_image
    
    def pil_to_tensor(self, pil_image):
        """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor"""
        if pil_image.mode == 'RGBA':
            pil_image = pil_image.convert('RGB')
        elif pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        numpy_image = np.array(pil_image).astype(np.float32)
        numpy_image = numpy_image / 255.0
        tensor = torch.from_numpy(numpy_image)
        tensor = tensor.unsqueeze(0)
        
        return tensor


NODE_CLASS_MAPPINGS = {
    "ImageAnnotateWithPanel": ImageAnnotateWithPanel,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageAnnotateWithPanel": "ğŸ”µBBå›¾åƒæ ‡æ³¨",
}
